# ğŸ³ Docker et Docker Compose pour MLOps

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-Backend-009688.svg)](https://fastapi.tiangolo.com/)
[![React](https://img.shields.io/badge/React-Frontend-61DAFB.svg)](https://reactjs.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg)](https://www.docker.com/)
[![Nginx](https://img.shields.io/badge/Nginx-Server-009639.svg)](https://nginx.org/)

## ğŸ“‹ Vue d'Ensemble

Application complÃ¨te de prÃ©diction basÃ©e sur le dataset Iris utilisant un modÃ¨le **RandomForest**. Ce projet dÃ©montre la **conteneurisation** et le **dÃ©ploiement** d'une application ML full-stack avec Docker et Docker Compose.

### ğŸ¯ Objectifs du Projet

- Conteneuriser une API ML avec Docker
- CrÃ©er un frontend React avec build multi-stage
- Orchestrer les services avec Docker Compose
- ImplÃ©menter les bonnes pratiques de dÃ©ploiement MLOps

### âœ¨ FonctionnalitÃ©s ClÃ©s

- **ğŸ API FastAPI** : Backend pour les prÃ©dictions ML
- **âš›ï¸ Frontend React** : Interface utilisateur moderne avec Vite
- **ğŸ³ Docker Multi-stage** : Images optimisÃ©es et lÃ©gÃ¨res
- **ğŸ”„ Docker Compose** : Orchestration multi-services
- **ğŸ“Š Monitoring** : Support Prometheus/Grafana (optionnel)

---

## ğŸ—ï¸ Architecture du Projet

```mermaid
graph TB
    User([ğŸ‘¤ Utilisateur]) --> Nginx[ğŸŒ Nginx<br/>:5174]
    Nginx --> React[âš›ï¸ React App<br/>Static Files]
    React --> API[ğŸ FastAPI<br/>:8000]
    API --> Model[ğŸ¤– RandomForest<br/>model.joblib]
    API --> DB[(ğŸ“Š SQLite)]
```

### Structure des Fichiers

```
iris-ai-service/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ Dockerfile              # Image Python pour l'API
â”‚   â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py            # Point d'entrÃ©e FastAPI
â”‚       â”œâ”€â”€ models.py          # ModÃ¨les Pydantic
â”‚       â”œâ”€â”€ db.py              # Gestion base de donnÃ©es
â”‚       â””â”€â”€ model/
â”‚           â”œâ”€â”€ model.joblib   # ModÃ¨le ML entraÃ®nÃ©
â”‚           â””â”€â”€ model_metadata.json
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ Dockerfile             # Multi-stage: Node + Nginx
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ nginx.conf            # Configuration Nginx
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.jsx
â”‚       â””â”€â”€ main.jsx
â”œâ”€â”€ monitoring/               # Prometheus/Grafana (optionnel)
â”œâ”€â”€ docker-compose.yml        # Orchestration des services
â””â”€â”€ README.md
```

---

## ğŸš€ Installation et DÃ©ploiement

### PrÃ©requis

- **Docker Desktop** (Windows/Mac) ou **Docker Engine** (Linux)
- **Docker Compose** v2.0+
- **Git**
- Ports **8000** et **5174** disponibles
- Au moins **2 GB de RAM**

### Ã‰tape 1 : Cloner le Projet

```bash
git clone https://github.com/chaima-massaoudi/Docker-et-Docker-Compose-pour-MLOps.git
cd iris-ai-service
```

### Ã‰tape 2 : Construction et Lancement

```bash
# Construire et lancer tous les services
docker compose up --build

# OU en mode dÃ©tachÃ© (arriÃ¨re-plan)
docker compose up --build -d
```

**Temps estimÃ© :** 3-5 minutes (premiÃ¨re fois)

### Ã‰tape 3 : VÃ©rification du DÃ©ploiement

```bash
docker compose ps
```

**RÃ©sultat attendu :**
```
NAME            STATE    PORTS
iris-api        Up       0.0.0.0:8000->8000/tcp
iris-frontend   Up       0.0.0.0:5174->80/tcp
```

### Ã‰tape 4 : Tester l'Application

- ğŸ“š **API Documentation (Swagger)** : http://localhost:8000/docs
- â¤ï¸ **API Health Check** : http://localhost:8000/health
- ğŸŒ **Frontend** : http://localhost:5174

---

## ğŸ³ DÃ©tails des Dockerfiles

### API Dockerfile (Python)

```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY app/ ./app/
EXPOSE 8000
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**CaractÃ©ristiques :**
- ğŸ Base lÃ©gÃ¨re : `python:3.11-slim` (~150 MB)
- ğŸ“¦ Installation optimisÃ©e avec `--no-cache-dir`
- ğŸš€ Serveur ASGI Uvicorn pour hautes performances

### Frontend Dockerfile (Multi-stage)

```dockerfile
# Build stage
FROM node:20-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build

# Production stage
FROM nginx:alpine
COPY --from=builder /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/conf.d/default.conf
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

**Avantages du Multi-stage Build :**
- âš¡ Image finale ultra-lÃ©gÃ¨re (~25 MB vs ~300 MB)
- ğŸ”¨ SÃ©paration build/runtime
- ğŸš€ Nginx performant pour fichiers statiques

---

## ğŸŒ API Endpoints

### Health Check

```http
GET /health
```

**RÃ©ponse :**
```json
{
  "status": "ok",
  "model_loaded": true,
  "model_type": "RandomForestClassifier",
  "features": ["sepal_length", "sepal_width", "petal_length", "petal_width"]
}
```

### PrÃ©diction

```http
POST /predict
Content-Type: application/json

{
  "sepal_length": 5.1,
  "sepal_width": 3.5,
  "petal_length": 1.4,
  "petal_width": 0.2
}
```

**RÃ©ponse :**
```json
{
  "prediction": "setosa",
  "probabilities": {
    "setosa": 0.95,
    "versicolor": 0.03,
    "virginica": 0.02
  }
}
```

---

## ğŸ”§ Commandes Docker Essentielles

### Gestion des Services

```bash
# DÃ©marrer tous les services
docker compose up -d

# ArrÃªter tous les services
docker compose down

# RedÃ©marrer un service
docker compose restart api

# Reconstruire sans cache
docker compose build --no-cache

# Voir l'Ã©tat des conteneurs
docker compose ps
```

### Logs et Debugging

```bash
# Voir les logs de tous les services
docker compose logs -f

# Voir les logs d'un service spÃ©cifique
docker compose logs -f api

# AccÃ©der au shell du conteneur API
docker compose exec api /bin/bash

# Voir les ressources utilisÃ©es
docker stats
```

### Nettoyage

```bash
# ArrÃªter et supprimer les conteneurs
docker compose down

# Supprimer aussi les volumes
docker compose down -v

# Nettoyage complet du systÃ¨me Docker
docker system prune -a --volumes
```

---

## ğŸ”’ Variables d'Environnement

| Variable | Service | Description | Valeur par DÃ©faut |
|----------|---------|-------------|-------------------|
| `API_PORT` | API | Port d'Ã©coute de l'API | 8000 |
| `CORS_ORIGINS` | API | Origines CORS autorisÃ©es | http://localhost:5174 |
| `VITE_API_BASE` | Frontend | URL de base de l'API | http://localhost:8000 |

---

## ğŸ› Troubleshooting

### Port dÃ©jÃ  utilisÃ©

```powershell
# Windows - Trouver le processus
netstat -ano | findstr :8000

# Tuer le processus (remplacer PID)
taskkill /PID <PID> /F
```

### Erreur CORS

1. VÃ©rifier que `VITE_API_BASE` est correct
2. VÃ©rifier que `CORS_ORIGINS` inclut l'URL du frontend
3. Rebuild le frontend : `docker compose up --build frontend`

### ModÃ¨le non trouvÃ©

```bash
# VÃ©rifier que le modÃ¨le existe
ls api/app/model/

# Reconstruire l'image
docker compose build api
```

---

## ğŸ“Š Monitoring (Optionnel)

Configuration Prometheus/Grafana disponible dans `monitoring/` :

- **Prometheus** : http://localhost:9090
- **Grafana** : http://localhost:3000 (admin/admin)

---

## ğŸ“š Ressources

- [Documentation FastAPI](https://fastapi.tiangolo.com/)
- [Documentation Docker](https://docs.docker.com/)
- [Documentation Docker Compose](https://docs.docker.com/compose/)
- [React + Vite](https://vitejs.dev/)
- [Docker Multi-stage Builds](https://docs.docker.com/build/building/multi-stage/)

---

**Bon dÃ©ploiement ! ğŸ³**
